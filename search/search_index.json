{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to SpeedyIBL Tutorial Overview Making decisions in changing and uncertain situations is one of the great challenges for humans. While it is challenging, humans, arguably, are well known for the ability to learn and adapt to changing conditions of choice. Thus, understanding how humans make decisions in dynamic situations has become a longstanding goal of cognitive theory. In this tutorial, we present a comprehensive overview of the Instance-based Learning Theory (IBLT) that emerged to explain human decision making as a dynamic process resulting from human interactions with the environment. We illustrate the IBLT process with concrete and step-by-step examples of how it operates. Furthermore, this tutorial will explore using SpeedyIBL, an efficient implementation of the full sets of mechanisms of IBLT, to handle a diverse range of decision-making tasks. The tutorial is designed as a combination of conceptual knowledge and practical, hands-on sessions for participants. Participants will practice the discussed concepts by writing their own implementation in Python using Google Colab, a free interactive online Jupyter notebook environment. Therefore, participants will be able to easily attend the tutorial via their web browsers, avoiding any complicated setup. The tutorial is divided into three sections focused on: technical guide for SpeedyIBL library to build computational IBL models; and practical demonstrations of how to use SpeedyIBL for a wide range of decision problems varying in the number of actions and the number of decision options and states. Logistics Course : SpeedyIBL Library for Instance-based Learning Theory: Applications for Decision-Making Tasks, Summer 2022 Location : Porter Hall 223-G (in-person) and online (Zoom) Time : 12PM to 3PM Instructors Ngoc Nguyen Email : ngocnt@cmu.edu Nhat Phan Email : dnphan@andrew.cmu.edu Prerequisites Passing knowledge of Python programming Basic understanding of cognitive Instance-based Learning Theory (IBLT). Learning Objectives By the end of this tutorial, participants will be able to: Understand the approach taken by the IBL theory to model learning and decisions from experience. Understand basic steps of creating an IBL agent that learns to make decisions with SpeedyIBL library. Apply SpeedyIBL to solve different kinds of decision-making tasks: binary choice tasks, sequential decision making in gridworld environment, and Atari games. Demos and Exercises There are two examples and four exercises included in the tutorial, which essentially create IBL agents that play a wide range of tasks. Through these examples and hands-on exercises, participants will: Learn to define a new task environment. Learn to create IBL agents that play different categories of tasks Understand how to manipulate different parameters of the IBL model, how to compute activation, retrieval probability, and blended values. Learn to run simulation experiments with IBL agents with different configurations (number of runs, etc.). Learn to plot and interpret the results. Activity Type of Task Demo 1 Single state task with immediate feedback Exercise 1 Single state task with immediate feedback Demo 2 Multi-state (sequential decison making) task with delayed feedback Excercise 2 Multi-state task with delayed feedback Excercise 3 Multi-state task in Gym OpenAI environment","title":"Home"},{"location":"#welcome-to-speedyibl-tutorial","text":"","title":"Welcome to SpeedyIBL Tutorial"},{"location":"#overview","text":"Making decisions in changing and uncertain situations is one of the great challenges for humans. While it is challenging, humans, arguably, are well known for the ability to learn and adapt to changing conditions of choice. Thus, understanding how humans make decisions in dynamic situations has become a longstanding goal of cognitive theory. In this tutorial, we present a comprehensive overview of the Instance-based Learning Theory (IBLT) that emerged to explain human decision making as a dynamic process resulting from human interactions with the environment. We illustrate the IBLT process with concrete and step-by-step examples of how it operates. Furthermore, this tutorial will explore using SpeedyIBL, an efficient implementation of the full sets of mechanisms of IBLT, to handle a diverse range of decision-making tasks. The tutorial is designed as a combination of conceptual knowledge and practical, hands-on sessions for participants. Participants will practice the discussed concepts by writing their own implementation in Python using Google Colab, a free interactive online Jupyter notebook environment. Therefore, participants will be able to easily attend the tutorial via their web browsers, avoiding any complicated setup. The tutorial is divided into three sections focused on: technical guide for SpeedyIBL library to build computational IBL models; and practical demonstrations of how to use SpeedyIBL for a wide range of decision problems varying in the number of actions and the number of decision options and states.","title":"Overview"},{"location":"#logistics","text":"Course : SpeedyIBL Library for Instance-based Learning Theory: Applications for Decision-Making Tasks, Summer 2022 Location : Porter Hall 223-G (in-person) and online (Zoom) Time : 12PM to 3PM","title":"Logistics"},{"location":"#instructors","text":"Ngoc Nguyen Email : ngocnt@cmu.edu Nhat Phan Email : dnphan@andrew.cmu.edu","title":"Instructors"},{"location":"#prerequisites","text":"Passing knowledge of Python programming Basic understanding of cognitive Instance-based Learning Theory (IBLT).","title":"Prerequisites"},{"location":"#learning-objectives","text":"By the end of this tutorial, participants will be able to: Understand the approach taken by the IBL theory to model learning and decisions from experience. Understand basic steps of creating an IBL agent that learns to make decisions with SpeedyIBL library. Apply SpeedyIBL to solve different kinds of decision-making tasks: binary choice tasks, sequential decision making in gridworld environment, and Atari games.","title":"Learning Objectives"},{"location":"#demos-and-exercises","text":"There are two examples and four exercises included in the tutorial, which essentially create IBL agents that play a wide range of tasks. Through these examples and hands-on exercises, participants will: Learn to define a new task environment. Learn to create IBL agents that play different categories of tasks Understand how to manipulate different parameters of the IBL model, how to compute activation, retrieval probability, and blended values. Learn to run simulation experiments with IBL agents with different configurations (number of runs, etc.). Learn to plot and interpret the results. Activity Type of Task Demo 1 Single state task with immediate feedback Exercise 1 Single state task with immediate feedback Demo 2 Multi-state (sequential decison making) task with delayed feedback Excercise 2 Multi-state task with delayed feedback Excercise 3 Multi-state task in Gym OpenAI environment","title":"Demos and Exercises"},{"location":"schedule/","text":"Tutorial Agenda (Tentative) Time Content Readings Material 15 mins Introduction to SpeedyIBL & SpeedyIBL installation Reading Note 20 mins Demo of IBL model for repeated Binary Choice task Reading Code 20 mins Hands-on exercise: Iowa Gambling Task (IGT) Exercise Demo Code 10 mins Sequential decision-making tasks in Gridworld environment Demo 30 mins Demo of IBL model for goal-seeking task in Gridworld environment (Scenario 1) : there is only one target and consuming the target terminates the game. Demo Code 1 Code 2 Code 3 10-min Break 25 mins Hands-on exercise: Goal-seeking task in Gridworld environment (Scenario 2) : there are two targets, one with a high value and the other with a low value. The goal is to find the higher value target. Exercise Demo Code 25 mins Hands-on exercise: Goal-seeking task in Gridworld environment (Scenario 3) : there are two targets, and the goal is to collect all the targets. Exercise Demo Code 30 mins Hands-on Exercise: SpeedyIBL for Atari game environments developed by Open Gym AI task (Atari games) : Ms. Pacman Exercise Atari ROMS Code","title":"Schedule"},{"location":"schedule/#tutorial-agenda-tentative","text":"Time Content Readings Material 15 mins Introduction to SpeedyIBL & SpeedyIBL installation Reading Note 20 mins Demo of IBL model for repeated Binary Choice task Reading Code 20 mins Hands-on exercise: Iowa Gambling Task (IGT) Exercise Demo Code 10 mins Sequential decision-making tasks in Gridworld environment Demo 30 mins Demo of IBL model for goal-seeking task in Gridworld environment (Scenario 1) : there is only one target and consuming the target terminates the game. Demo Code 1 Code 2 Code 3 10-min Break 25 mins Hands-on exercise: Goal-seeking task in Gridworld environment (Scenario 2) : there are two targets, one with a high value and the other with a low value. The goal is to find the higher value target. Exercise Demo Code 25 mins Hands-on exercise: Goal-seeking task in Gridworld environment (Scenario 3) : there are two targets, and the goal is to collect all the targets. Exercise Demo Code 30 mins Hands-on Exercise: SpeedyIBL for Atari game environments developed by Open Gym AI task (Atari games) : Ms. Pacman Exercise Atari ROMS Code","title":"Tutorial Agenda (Tentative)"},{"location":"resources/paper/","text":"Related papers Instance-based Learning Theory in dynamic decision making Minimap: An Interactive Dynamic Decision Making Game for Search and Rescue Missions","title":"Related papers"},{"location":"resources/paper/#related-papers","text":"Instance-based Learning Theory in dynamic decision making Minimap: An Interactive Dynamic Decision Making Game for Search and Rescue Missions","title":"Related papers"},{"location":"resources/speedyibl/","text":"SpeedyIBL SpeedyIBL Github SpeedyIBL Code","title":"SpeedyIBL"},{"location":"resources/speedyibl/#speedyibl","text":"SpeedyIBL Github SpeedyIBL Code","title":"SpeedyIBL"}]}